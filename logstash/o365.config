input {
    file { 
        path => "<tsv_moniter>/*.csv"
        type => "o365_tsv" 
        start_position => "beginning"
    }

    file { 
        path => "<csv_moniter>/*.csv"
        type => "o365_csv" 
        start_position => "beginning"
    }
}

filter {
    if ([type] == "o365_tsv") {
        csv {
            columns => ["CreationDate", "UserIds", "Operations", "AuditData"]
            skip_header => "true"
            add_tag => [ "o365_csv_log" ]
            # Insert a literal tab for a separator
            separator => "  " 
        }

        date {
            match => [ "CreationDate", "ISO8601"]
        }

        json {
            # Need to parse out embedded JSON
            source => "AuditData"
        }

        geoip {
            database => "<pointer_to_maxmind_db>"
            source => "ClientIP"
            target => "client_geo"
        }
    }

    if ([type] == "o365_csv") {
        csv {
            columns => ["PSComputerName", "RunspaceId", "PSShowComputerName", "RecordType", "CreationDate", "UserIds", "Operations", "AuditData", "ResultIndex", "ResultCount", "Identity", "IsValid", "ObjectState"]
            skip_header => "true"
            
            # Need to drop that pesky second header
            if ([message] =~ /^#/) {
                drop {}
            }
        }

        date {
            match => [ "CreationDate", "ISO8601" ]
        }

        # Need to parse out embedded JSON
        json {
            source => "AuditData"
        }

        geoip {
            database => "<pointer_to_maxmind_db>"
            source => "ClientIP"
            target => "client_geo"
        }
    }
}

output {
    elasticsearch {
        # Change me to reflect your Elastic server
        hosts => ["<elk_server>:<elk_port"]
        index => "o365_logs"
    }
}